import streamlit as st
import pandas as pd
import random
import os
import json
import re
import difflib
import asyncio
import edge_tts
from io import BytesIO
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder

# --- è¨­å®šå€ ---
DATA_FILENAME = 'phrases.xlsx'
MISTAKE_FILENAME = 'mistakes.json'
TEMP_AUDIO_FILE = "temp_voice.mp3" # æš«å­˜æª”å

# --- 1. åŸºç¤å‡½å¼ ---

@st.cache_data
def load_data():
    if not os.path.exists(DATA_FILENAME): return [], {}, []
    try:
        df = pd.read_excel(DATA_FILENAME).fillna("")
        data_list = df.to_dict('records')
        valid_data = []
        synonym_map = {} 
        all_meanings = [] 

        for row in data_list:
            p = str(row.get('phrase', '')).strip()
            s = str(row.get('sentence', '')).strip()
            a = str(row.get('Answer', '')).strip()
            m = str(row.get('meaning', '')).strip()
            
            if p and s:
                if not a: a = p
                valid_data.append({"phrase": p, "meaning": m, "sentence": s, "answer": a})
                if m not in all_meanings: all_meanings.append(m)
                
                if m not in synonym_map: synonym_map[m] = []
                if p.lower() not in synonym_map[m]: synonym_map[m].append(p.lower())
                if a.lower() not in synonym_map[m]: synonym_map[m].append(a.lower())

        return valid_data, synonym_map, all_meanings
    except: return [], {}, []

def load_mistakes():
    if not os.path.exists(MISTAKE_FILENAME): return []
    try:
        with open(MISTAKE_FILENAME, 'r', encoding='utf-8') as f: return json.load(f)
    except: return []

def save_mistakes(mistake_list):
    try:
        with open(MISTAKE_FILENAME, 'w', encoding='utf-8') as f:
            json.dump(mistake_list, f, ensure_ascii=False, indent=4)
    except: pass

# --- Edge-TTS å­˜æª”æ¨¡å¼ ---
async def _edge_tts_save(text, voice="en-US-GuyNeural"):
    try:
        clean_text = text.replace("_", " ")
        communicate = edge_tts.Communicate(clean_text, voice)
        await communicate.save(TEMP_AUDIO_FILE)
        return True
    except Exception as e:
        print(f"EdgeTTS Error: {e}")
        return False

def get_audio_bytes(text):
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        success = loop.run_until_complete(_edge_tts_save(text))
        
        if success and os.path.exists(TEMP_AUDIO_FILE):
            with open(TEMP_AUDIO_FILE, "rb") as f:
                audio_bytes = f.read()
            return audio_bytes
        else:
            return None
    except Exception as e:
        st.error(f"èªéŸ³ç”Ÿæˆå¤±æ•—: {e}")
        return None

def generate_diff(user_text, target_text):
    s = difflib.SequenceMatcher(None, user_text.lower(), target_text.lower())
    html = []
    for opcode, a0, a1, b0, b1 in s.get_opcodes():
        if opcode == 'equal':
            html.append(f"<span style='color:green; font-weight:bold'>{target_text[b0:b1]}</span>")
        elif opcode == 'insert':
            html.append(f"<span style='color:red; text-decoration:underline; background-color:#ffe6e6'>[{target_text[b0:b1]}]</span>")
        elif opcode == 'delete':
             html.append(f"<span style='color:gray; text-decoration:line-through'>{user_text[a0:a1]}</span>")
        elif opcode == 'replace':
            html.append(f"<span style='color:gray; text-decoration:line-through'>{user_text[a0:a1]}</span>")
            html.append(f"<span style='color:red; background-color:#ffe6e6'>[{target_text[b0:b1]}]</span>")
    return "".join(html)

def transcribe_audio_bytes(audio_bytes):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(BytesIO(audio_bytes)) as source:
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language='en-US')
            return text
    except sr.UnknownValueError:
        return "Not Recognized"
    except sr.RequestError:
        return "API Error"
    except Exception as e:
        return str(e)

# --- 2. ç‹€æ…‹åˆå§‹åŒ– ---

if 'initialized' not in st.session_state:
    data, syn_map, meanings = load_data()
    st.session_state.all_phrases = data
    st.session_state.synonym_map = syn_map
    st.session_state.all_meanings = meanings
    st.session_state.mistakes = load_mistakes()
    
    st.session_state.current_q = None
    st.session_state.mode = None
    st.session_state.feedback = None
    st.session_state.audio_data = None
    st.session_state.q_audio_data = None
    st.session_state.user_audio_bytes = None # [æ–°åŠŸèƒ½] å­˜ä½¿ç”¨è€…çš„éŒ„éŸ³
    st.session_state.options = [] 
    st.session_state.show_hint = False
    st.session_state.user_answer_key = "" 
    st.session_state.initialized = True

# --- 3. æ ¸å¿ƒé‚è¼¯ ---

def pick_new_question():
    mistakes = st.session_state.mistakes
    all_phrases = st.session_state.all_phrases
    
    if not all_phrases: return

    target_item = None
    is_review = False
    
    if mistakes and random.random() < 0.7:
        review_phrase = random.choice(mistakes)
        target_item = next((item for item in all_phrases if item['phrase'] == review_phrase), None)
        if target_item: is_review = True
        else:
            mistakes.remove(review_phrase)
            save_mistakes(mistakes)
            st.session_state.mistakes = mistakes

    if not target_item:
        target_item = random.choice(all_phrases)

    mode = random.choice(['phrase', 'sentence', 'listening', 'choice', 'speaking'])
    
    st.session_state.current_q = target_item
    st.session_state.mode = mode
    st.session_state.is_review = is_review
    st.session_state.feedback = None
    st.session_state.audio_data = None
    st.session_state.q_audio_data = None
    st.session_state.user_audio_bytes = None # [é‡ç½®] æ¸…ç©ºä¸Šä¸€é¡Œçš„éŒ„éŸ³
    st.session_state.show_hint = False 
    
    full_s = re.sub(r'_+', target_item['answer'], target_item['sentence'])
    
    if mode == 'listening' or mode == 'speaking':
        st.session_state.q_audio_data = get_audio_bytes(full_s)
    elif mode == 'choice':
        st.session_state.q_audio_data = get_audio_bytes(target_item['phrase'])
        correct = target_item['meaning']
        distractors = random.sample([m for m in st.session_state.all_meanings if m != correct], 3)
        opts = distractors + [correct]
        random.shuffle(opts)
        st.session_state.options = opts

def check_answer(user_input):
    item = st.session_state.current_q
    mode = st.session_state.mode
    
    if not item: return

    # Clean input
    user_clean = user_input.strip()

    if mode == 'phrase' or mode == 'choice':
        target_ans = item['phrase'] 
        if mode == 'choice': 
            is_correct = (user_clean == item['meaning'])
            target_ans = item['meaning']
            if is_correct:
                handle_correct(item, re.sub(r'_+', item['answer'], item['sentence']))
            else:
                handle_wrong(item, target_ans, re.sub(r'_+', item['answer'], item['sentence']))
            return 

    elif mode == 'speaking':
        target_ans = re.sub(r'_+', item['answer'], item['sentence'])
    else:
        target_ans = item['answer']

    # Logic for non-choice modes
    def clean(t): return re.sub(r'[^\w\s]', '', t.lower()).strip()
    is_correct = clean(user_clean) == clean(target_ans)
    
    if not is_correct:
        # 1. Tense/Form Check
        if mode in ['sentence', 'listening', 'speaking']:
             phrase_base = item['phrase']
             if clean(user_clean) == clean(phrase_base) and clean(phrase_base) != clean(target_ans):
                full_s = re.sub(r'_+', item['answer'], item['sentence'])
                msg = f"""
                âš ï¸ **ç”¨è©æ­£ç¢ºï¼Œä½†å‹æ…‹/æ™‚æ…‹ä¸å°å–”ï¼** <br>
                ä½ è¼¸å…¥: `{user_clean}` (åŸå½¢)<br>
                æ­£ç¢ºæ‡‰ç‚º: **{target_ans}**
                """
                st.session_state.feedback = {"type": "warning", "msg": msg}
                st.session_state.audio_data = get_audio_bytes(full_s)
                return

        # 2. Synonym Check (Skip speaking)
        if mode != 'speaking':
            syn_map = st.session_state.synonym_map
            current_meaning = item['meaning']
            if current_meaning in syn_map and user_clean.lower() in syn_map[current_meaning]:
                full_s = re.sub(r'_+', item['answer'], item['sentence'])
                msg = f"âš ï¸ **æ„æ€æ­£ç¢ºï¼** (ä½ ç­” `{user_clean}`) ä½†é€™é¡ŒæŒ‡å®šç­”æ¡ˆæ˜¯ **{target_ans}**"
                st.session_state.feedback = {"type": "warning", "msg": msg}
                st.session_state.audio_data = get_audio_bytes(full_s)
                return

    full_sentence_str = re.sub(r'_+', item['answer'], item['sentence'])
    
    if is_correct:
        handle_correct(item, full_sentence_str)
    else:
        handle_wrong(item, target_ans, full_sentence_str, user_clean)

def handle_correct(item, full_s):
    msg = "âœ… Correct! ç­”å°äº†ï¼"
    if item['phrase'] in st.session_state.mistakes:
        st.session_state.mistakes.remove(item['phrase'])
        save_mistakes(st.session_state.mistakes)
        msg += " (å·²ç§»é™¤éŒ¯é¡Œ ğŸ‰)"
    
    st.session_state.feedback = {"type": "success", "msg": msg}
    st.session_state.audio_data = get_audio_bytes(full_s)

def handle_wrong(item, target_text, full_s, user_input=""):
    diff_html = ""
    if user_input:
        diff_html = generate_diff(user_input, target_text)
        diff_display = f"<br>å·®ç•°æ¯”å°: {diff_html}"
    else:
        diff_display = ""

    msg = f"âŒ ç­”éŒ¯äº†ï¼<br>æ­£ç¢ºç­”æ¡ˆ: **{target_text}**{diff_display}<br>å®Œæ•´ä¾‹å¥: *{full_s}*"
    
    if item['phrase'] not in st.session_state.mistakes:
        st.session_state.mistakes.append(item['phrase'])
        save_mistakes(st.session_state.mistakes)
    
    st.session_state.feedback = {"type": "error", "msg": msg}
    st.session_state.audio_data = get_audio_bytes(full_s)

def toggle_hint():
    st.session_state.show_hint = True

# --- 4. ä»‹é¢ä½ˆå±€ ---

st.set_page_config(page_title="ç©¶æ¥µè‹±æ–‡ç‰¹è¨“", page_icon="ğŸ§ ")

with st.sidebar:
    st.header("ğŸ“Š å­¸ç¿’æ§åˆ¶å°")
    st.metric("ğŸ’€ éŒ¯é¡Œæœ¬", f"{len(st.session_state.mistakes)} é¡Œ")
    with st.expander("ğŸ—‘ï¸ ç®¡ç†éŒ¯é¡Œ"):
        if st.session_state.mistakes:
            to_remove = st.multiselect("ç§»é™¤å·²å­¸æœƒ:", st.session_state.mistakes)
            if st.button("ç¢ºèªåˆªé™¤"):
                for w in to_remove:
                    if w in st.session_state.mistakes: st.session_state.mistakes.remove(w)
                save_mistakes(st.session_state.mistakes)
                st.rerun()
        else: st.write("éŒ¯é¡Œæœ¬æ˜¯ç©ºçš„ï¼")
    st.divider()
    if st.button("ğŸ”„ é‡æ–°è¼‰å…¥"):
        st.cache_data.clear()
        st.session_state.initialized = False
        st.rerun()

st.title("ğŸ§  ç©¶æ¥µè‹±æ–‡ç‰¹è¨“ (Edge-TTS Ver.)")

if st.session_state.current_q is None:
    pick_new_question()

q = st.session_state.current_q
mode = st.session_state.mode

if st.session_state.is_review: st.warning("ğŸ’€ éŒ¯é¡Œè¤‡ç¿’ä¸­...")

col1, col2 = st.columns([1, 4])
with col1:
    if mode == 'phrase': st.info("ğŸ“ è€ƒç‰‡èª")
    elif mode == 'sentence': st.success("ğŸ—£ï¸ è€ƒä¾‹å¥")
    elif mode == 'listening': st.warning("ğŸ‘‚ è½å¯«")
    elif mode == 'choice': st.error("âš¡ è½éŸ³é¸ç¾©")
    elif mode == 'speaking': st.error("ğŸ™ï¸ å£èªªç‰¹è¨“")

# --- é¡Œç›®é¡¯ç¤ºå€ ---
with col2:
    if mode == 'choice':
        st.subheader("è«‹è½ç™¼éŸ³ï¼Œé¸å‡ºæ­£ç¢ºæ„æ€ï¼š")
        if st.session_state.q_audio_data:
            st.audio(st.session_state.q_audio_data, format='audio/mpeg')
        else:
            st.warning("âš ï¸ éŸ³æª”ç”Ÿæˆå¤±æ•—")
            
    elif mode == 'listening':
        st.subheader("è«‹è½å®Œæ•´å¥å­ï¼Œå¡«å…¥ç©ºæ ¼ï¼š")
        if st.session_state.q_audio_data:
            st.audio(st.session_state.q_audio_data, format='audio/mpeg')
        else:
            st.warning("âš ï¸ éŸ³æª”ç”Ÿæˆå¤±æ•—")
        clean_s = re.sub(r'_+', ' ______ ', q['sentence'])
        st.markdown(f"**{clean_s}**")
        
    elif mode == 'speaking':
        full_display = re.sub(r'_+', q['answer'], q['sentence'])
        st.subheader("è«‹å¤§è²å”¸å‡ºä»¥ä¸‹å¥å­ï¼š")
        st.markdown(f"### ğŸ—£ï¸ {full_display}")
        st.info("è«‹ä½¿ç”¨ä¸‹æ–¹éŒ„éŸ³æŒ‰éˆ•é€²è¡Œä½œç­”ã€‚")
        
    else: 
        st.subheader(f"ä¸­æ–‡: {q['meaning']}")
        if mode == 'sentence':
            clean_s = re.sub(r'_+', ' ______ ', q['sentence'])
            st.markdown(f"#### {clean_s}")

# --- æç¤ºå€ ---
if mode not in ['choice', 'speaking'] and not st.session_state.feedback:
    target = q['phrase'] if mode == 'phrase' else q['answer']
    hint_text = f"é¦–å­—æ¯: **{target[0]}...** (ç¸½é•·åº¦: {len(target)})"
    if st.session_state.show_hint: st.info(f"ğŸ’¡ æç¤º: {hint_text}")
    else: st.button("ğŸ’¡ çµ¦æˆ‘ä¸€é»æç¤º (Scaffolding)", on_click=toggle_hint)

st.divider()

# --- ä½œç­”å€ ---
has_answered = st.session_state.feedback is not None

if mode == 'choice':
    st.write("è«‹é¸æ“‡:")
    cols = st.columns(2)
    for i, opt in enumerate(st.session_state.options):
        cols[i%2].button(
            opt, 
            use_container_width=True, 
            on_click=check_answer, 
            args=(opt,),
            disabled=has_answered 
        )

elif mode == 'speaking':
    if not has_answered:
        col_rec, col_msg = st.columns([1, 3])
        with col_rec:
            audio_blob = mic_recorder(
                start_prompt="ğŸ™ï¸ é–‹å§‹éŒ„éŸ³", 
                stop_prompt="â¹ï¸ åœæ­¢ä¸¦é€å‡º", 
                key='my_recorder',
                format="wav"
            )
        
        with col_msg:
            if audio_blob:
                # [æ–°åŠŸèƒ½] 1. å„²å­˜ä½¿ç”¨è€…éŒ„éŸ³ä¾›ç¨å¾Œå›æ”¾
                st.session_state.user_audio_bytes = audio_blob['bytes']

                st.write("ğŸ”„ æ­£åœ¨è¾¨è­˜...")
                audio_bytes = audio_blob['bytes']
                text_result = transcribe_audio_bytes(audio_bytes)
                
                if text_result == "Not Recognized":
                    st.warning("ğŸ˜“ è½ä¸å¤ªæ¸…æ¥š")
                elif text_result == "API Error":
                    st.error("âš ï¸ èªéŸ³æœå‹™é€£ç·šéŒ¯èª¤")
                else:
                    st.success(f"ğŸ‘‚ ç³»çµ±è½åˆ°ï¼š **{text_result}**")
                    check_answer(text_result)
                    st.rerun()

        st.markdown("")
        if st.button("ğŸ˜¶ ç¾åœ¨ä¸æ–¹ä¾¿èªªï¼Œè·³éé€™é¡Œ"):
            pick_new_question() 
            st.rerun()          
    else:
        st.info("ğŸ¤ éŒ„éŸ³çµæŸï¼Œè«‹æŸ¥çœ‹ä¸‹æ–¹å›é¥‹ä¸¦æŒ‰ä¸‹ä¸€é¡Œã€‚")

else:
    with st.form(key='answer_form', clear_on_submit=True):
        user_input_val = st.text_input(
            "è«‹è¼¸å…¥ç­”æ¡ˆ (æŒ‰ Enter é€å‡º):", 
            key="user_input_form",
            disabled=has_answered 
        )
        submitted = st.form_submit_button(
            "é€å‡ºç­”æ¡ˆ", 
            disabled=has_answered
        )

    if submitted:
        check_answer(user_input_val)

# --- å›é¥‹å€ ---
if st.session_state.feedback:
    fb = st.session_state.feedback
    
    if fb['type'] == 'success': st.success(fb['msg'])
    elif fb['type'] == 'warning': st.warning(fb['msg'], icon="âš ï¸")
    else: 
        st.markdown(fb['msg'], unsafe_allow_html=True)
        st.error("åŠ æ²¹ï¼å†è©¦ä¸€æ¬¡ï¼")
    
    # é¡¯ç¤ºæ¨™æº–ç™¼éŸ³ (Edge-TTS)
    if st.session_state.audio_data:
        st.write("ğŸ”Š æ¨™æº–ç™¼éŸ³ (Edge-TTS)ï¼š")
        st.audio(st.session_state.audio_data, format='audio/mpeg', start_time=0)

    # [æ–°åŠŸèƒ½] é¡¯ç¤ºä½¿ç”¨è€…å‰›å‰›çš„éŒ„éŸ³ (å¦‚æœæœ‰)
    if st.session_state.user_audio_bytes:
        st.write("ğŸ¤ ä½ çš„éŒ„éŸ³å›æ”¾ï¼š")
        st.audio(st.session_state.user_audio_bytes, format='audio/wav')

    st.markdown("---")
    st.button("ğŸ‘‰ ä¸‹ä¸€é¡Œ (Next)", on_click=pick_new_question, type="primary", key="btn_next")
